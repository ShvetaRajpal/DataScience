{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "4_Statefarm_convnet_pretrained_features.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNzYFM4VKmvHruhYCUPBFok",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kiranmuloor/DataScience/blob/master/CNN/Statefarm/4_Statefarm_convnet_pretrained_features.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SDqtk0IZUFMW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "8281054b-2c44-4b0e-e9f1-93ab92dd5a57"
      },
      "source": [
        "#This method does not use Data Augmentation\n",
        "from keras.applications import VGG16\n",
        "#Just reuse the bottom convolutional base of VGG16 model as its more generic, top will be related to specific classes so not used\n",
        "conv_base = VGG16(weights='imagenet',include_top=False,input_shape=(150, 150, 3))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 6s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O2iopGYUUoGy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "8c4d52e4-9463-4750-83bb-8e9b8e054dc6"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p1MxpBgeU9I7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Extracting features using the pretrained convolutional base\n",
        "import os\n",
        "import numpy as np\n",
        "from keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hs_7sQ2ZVMq_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "base_dir = '/content/drive/My Drive/Datascience/ClassWork/DeepLearning/CNN/Statefarms/'\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "validation_dir = os.path.join(base_dir, 'validation')\n",
        "test_dir = os.path.join(base_dir, 'validation')\n",
        "datagen = ImageDataGenerator(rescale=1./255)\n",
        "batch_size = 20\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g2r0RTneVbns",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "808fdf5d-86be-4216-9c81-d0e97060fa38"
      },
      "source": [
        "def extract_features(directory, sample_count):\n",
        "    features = np.zeros(shape=(sample_count, 4, 4, 512))\n",
        "    labels = np.zeros(shape=(sample_count))\n",
        "    generator = datagen.flow_from_directory(\n",
        "    directory,\n",
        "    target_size=(150, 150),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary')\n",
        "    i = 0\n",
        "    for inputs_batch, labels_batch in generator:\n",
        "        features_batch = conv_base.predict(inputs_batch)\n",
        "        features[i * batch_size : (i + 1) * batch_size] = features_batch\n",
        "        labels[i * batch_size : (i + 1) * batch_size] = labels_batch\n",
        "        #print(labels_batch.shape)\n",
        "        i += 1\n",
        "        #Note that because generators yield data indefinitely in a loop,you must break after every image has been seen once\n",
        "        if i * batch_size >= sample_count:\n",
        "            break\n",
        "    return features, labels\n",
        "train_features, train_labels = extract_features(train_dir, 2000)\n",
        "validation_features, validation_labels = extract_features(validation_dir, 1000)\n",
        "test_features, test_labels = extract_features(test_dir, 1000)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 5488 images belonging to 10 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pbhj7AypVfsh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#The extracted features are currently of shape (samples, 4, 4, 512). You’ll feed them\n",
        "#to a densely connected classifier, so first you must flatten them to (samples, 8192):\n",
        "\n",
        "train_features = np.reshape(train_features, (2000, 4 * 4 * 512))\n",
        "validation_features = np.reshape(validation_features, (1000, 4 * 4 * 512))\n",
        "test_features = np.reshape(test_features, (1000, 4 * 4 * 512))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hiV1KQfAVoYr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.utils.np_utils import to_categorical\n",
        "num_classes = len(validation_generator.class_indices)\n",
        "validation_labels = validation_generator.classes\n",
        "validation_labels = to_categorical(validation_labels, num_classes=num_classes)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VTBLQZKBV3_6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Defining and Training the Densely connected classifier\n",
        "from keras import models\n",
        "from keras import layers\n",
        "from keras import optimizers\n",
        "model = models.Sequential()\n",
        "model.add(layers.Dense(256, activation='relu', input_dim=4 * 4 * 512))\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Dense(num_classes, activation='sigmoid'))\n",
        "\n",
        "model.compile(optimizer=optimizers.RMSprop(lr=2e-5),\n",
        "loss='binary_crossentropy',\n",
        "metrics=['acc'])\n",
        "\n",
        "history = model.fit(train_features, train_labels,\n",
        "epochs=10,\n",
        "batch_size=20,\n",
        "validation_data=(validation_features, validation_labels))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CJo-jmalWcm1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Plotting the results\n",
        "import matplotlib.pyplot as plt\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(1, len(acc) + 1)\n",
        "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "plt.figure()\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CXesdpU6Whbs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}