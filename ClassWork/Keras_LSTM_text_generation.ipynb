{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "colab": {
      "name": "Keras_LSTM_text_generation.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kiranmuloor/DataScience/blob/master/ClassWork/Keras_LSTM_text_generation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uFERq_ZvdKDH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#import required libraries\n",
        "import numpy\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import LSTM\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.utils import np_utils\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I7XpYjlvdKDr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0297262a-6712-482b-b02a-b96111f36614"
      },
      "source": [
        "#Load the file\n",
        "# load text and covert to lowercase\n",
        "filename = \"wonderland.txt\"\n",
        "raw_text = open(filename, 'r', encoding='utf-8').read()\n",
        "raw_text = raw_text.lower()\n",
        "raw_text[0:100]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\ufeffproject gutenberg's alice's adventures in wonderland, by lewis carroll\\n\\nthis ebook is for the use o\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gsCT1WsjdKEG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create mapping of unique chars to integers\n",
        "chars = sorted(list(set(raw_text)))\n",
        "char_to_int = dict((c, i) for i, c in enumerate(chars))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eCQsHzgxdKEm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9c43cfef-122f-4193-efb2-dbb9cf6623db"
      },
      "source": [
        "chars[0:10]"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['\\n', ' ', '!', '\"', '#', '$', '%', \"'\", '(', ')']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "suJWXu-5dKFL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "aaab61ce-9524-48bf-df4e-a31e34aa4a22"
      },
      "source": [
        "char_to_int"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'\\n': 0,\n",
              " ' ': 1,\n",
              " '!': 2,\n",
              " '\"': 3,\n",
              " '#': 4,\n",
              " '$': 5,\n",
              " '%': 6,\n",
              " \"'\": 7,\n",
              " '(': 8,\n",
              " ')': 9,\n",
              " '*': 10,\n",
              " ',': 11,\n",
              " '-': 12,\n",
              " '.': 13,\n",
              " '/': 14,\n",
              " '0': 15,\n",
              " '1': 16,\n",
              " '2': 17,\n",
              " '3': 18,\n",
              " '4': 19,\n",
              " '5': 20,\n",
              " '6': 21,\n",
              " '7': 22,\n",
              " '8': 23,\n",
              " '9': 24,\n",
              " ':': 25,\n",
              " ';': 26,\n",
              " '?': 27,\n",
              " '@': 28,\n",
              " '[': 29,\n",
              " ']': 30,\n",
              " '_': 31,\n",
              " 'a': 32,\n",
              " 'b': 33,\n",
              " 'c': 34,\n",
              " 'd': 35,\n",
              " 'e': 36,\n",
              " 'f': 37,\n",
              " 'g': 38,\n",
              " 'h': 39,\n",
              " 'i': 40,\n",
              " 'j': 41,\n",
              " 'k': 42,\n",
              " 'l': 43,\n",
              " 'm': 44,\n",
              " 'n': 45,\n",
              " 'o': 46,\n",
              " 'p': 47,\n",
              " 'q': 48,\n",
              " 'r': 49,\n",
              " 's': 50,\n",
              " 't': 51,\n",
              " 'u': 52,\n",
              " 'v': 53,\n",
              " 'w': 54,\n",
              " 'x': 55,\n",
              " 'y': 56,\n",
              " 'z': 57,\n",
              " '\\ufeff': 58}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ssqjGu7dKFg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "95ca27e2-5c47-46d2-ff3c-7964df272b81"
      },
      "source": [
        "#Summarize the Dataset\n",
        "n_chars = len(raw_text)\n",
        "n_vocab = len(chars)\n",
        "print (\"Total Characters: \", n_chars)\n",
        "print (\"Total Vocab: \", n_vocab)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Characters:  163781\n",
            "Total Vocab:  59\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tNHgASRedKF2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6683b79e-5f91-495c-a9c0-c4d54705c4c9"
      },
      "source": [
        "# prepare the dataset of input to output pairs encoded as integers\n",
        "seq_length = 100\n",
        "dataX = []\n",
        "dataY = []\n",
        "for i in range(0, n_chars - seq_length, 1):\n",
        "\tseq_in = raw_text[i:i + seq_length]\n",
        "\tseq_out = raw_text[i + seq_length]\n",
        "\tdataX.append([char_to_int[char] for char in seq_in])\n",
        "\tdataY.append(char_to_int[seq_out])\n",
        "n_patterns = len(dataX)\n",
        "print (\"Total Patterns: \", n_patterns)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Patterns:  163681\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uy1XwISGdKGO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# reshape X to be [samples, time steps, features]\n",
        "X = numpy.reshape(dataX, (n_patterns, seq_length, 1))\n",
        "# normalize\n",
        "X = X / float(n_vocab)\n",
        "# one hot encode the output variable\n",
        "y = np_utils.to_categorical(dataY)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TERKjO4kdKGV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 879
        },
        "outputId": "eed70058-21d6-46da-e1c8-4c9a95211927"
      },
      "source": [
        "X"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[0.98305085],\n",
              "        [0.79661017],\n",
              "        [0.83050847],\n",
              "        ...,\n",
              "        [0.61016949],\n",
              "        [0.01694915],\n",
              "        [0.77966102]],\n",
              "\n",
              "       [[0.79661017],\n",
              "        [0.83050847],\n",
              "        [0.77966102],\n",
              "        ...,\n",
              "        [0.01694915],\n",
              "        [0.77966102],\n",
              "        [0.62711864]],\n",
              "\n",
              "       [[0.83050847],\n",
              "        [0.77966102],\n",
              "        [0.69491525],\n",
              "        ...,\n",
              "        [0.77966102],\n",
              "        [0.62711864],\n",
              "        [0.01694915]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[0.86440678],\n",
              "        [0.77966102],\n",
              "        [0.01694915],\n",
              "        ...,\n",
              "        [0.77966102],\n",
              "        [0.77966102],\n",
              "        [0.71186441]],\n",
              "\n",
              "       [[0.77966102],\n",
              "        [0.01694915],\n",
              "        [0.66101695],\n",
              "        ...,\n",
              "        [0.77966102],\n",
              "        [0.71186441],\n",
              "        [0.84745763]],\n",
              "\n",
              "       [[0.01694915],\n",
              "        [0.66101695],\n",
              "        [0.61016949],\n",
              "        ...,\n",
              "        [0.71186441],\n",
              "        [0.84745763],\n",
              "        [0.22033898]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i30H6D0WdKGs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "outputId": "c40a3a6e-985d-49fd-e54b-205229c1ffd9"
      },
      "source": [
        "y"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 1., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [1., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HZQcCD65dKGw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define the LSTM model\n",
        "model = Sequential()\n",
        "model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2])))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(y.shape[1], activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QyBobbDXdKHP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "23616e24-b244-435b-a84e-6dddb5a97be0"
      },
      "source": [
        "X.shape[1]\n",
        "X.shape[2]"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DTgc3aAgdKHw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define the checkpoint\n",
        "filepath=\"weights-improvement-{epoch:02d}-{loss:.4f}.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
        "callbacks_list = [checkpoint]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LgLtnCDzgDUd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dF2UniWwdKH-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5efda945-ac54-4112-a995-94ca93bd0394"
      },
      "source": [
        "#Fitting the model\n",
        "model.fit(X, y, epochs=20, batch_size=128, callbacks=callbacks_list)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "163681/163681 [==============================] - 309s 2ms/step - loss: 2.0657\n",
            "\n",
            "Epoch 00001: loss improved from 2.08759 to 2.06574, saving model to weights-improvement-01-2.0657.hdf5\n",
            "Epoch 2/20\n",
            "163681/163681 [==============================] - 309s 2ms/step - loss: 2.0448\n",
            "\n",
            "Epoch 00002: loss improved from 2.06574 to 2.04482, saving model to weights-improvement-02-2.0448.hdf5\n",
            "Epoch 3/20\n",
            "163681/163681 [==============================] - 308s 2ms/step - loss: 2.0243\n",
            "\n",
            "Epoch 00003: loss improved from 2.04482 to 2.02430, saving model to weights-improvement-03-2.0243.hdf5\n",
            "Epoch 4/20\n",
            "163681/163681 [==============================] - 307s 2ms/step - loss: 2.0045\n",
            "\n",
            "Epoch 00004: loss improved from 2.02430 to 2.00453, saving model to weights-improvement-04-2.0045.hdf5\n",
            "Epoch 5/20\n",
            "163681/163681 [==============================] - 305s 2ms/step - loss: 1.9873\n",
            "\n",
            "Epoch 00005: loss improved from 2.00453 to 1.98728, saving model to weights-improvement-05-1.9873.hdf5\n",
            "Epoch 6/20\n",
            "163681/163681 [==============================] - 303s 2ms/step - loss: 1.9694\n",
            "\n",
            "Epoch 00006: loss improved from 1.98728 to 1.96941, saving model to weights-improvement-06-1.9694.hdf5\n",
            "Epoch 7/20\n",
            "163681/163681 [==============================] - 303s 2ms/step - loss: 1.9550\n",
            "\n",
            "Epoch 00007: loss improved from 1.96941 to 1.95498, saving model to weights-improvement-07-1.9550.hdf5\n",
            "Epoch 8/20\n",
            "163681/163681 [==============================] - 306s 2ms/step - loss: 1.9405\n",
            "\n",
            "Epoch 00008: loss improved from 1.95498 to 1.94047, saving model to weights-improvement-08-1.9405.hdf5\n",
            "Epoch 9/20\n",
            "163681/163681 [==============================] - 307s 2ms/step - loss: 1.9256\n",
            "\n",
            "Epoch 00009: loss improved from 1.94047 to 1.92564, saving model to weights-improvement-09-1.9256.hdf5\n",
            "Epoch 10/20\n",
            "163681/163681 [==============================] - 308s 2ms/step - loss: 1.9095\n",
            "\n",
            "Epoch 00010: loss improved from 1.92564 to 1.90947, saving model to weights-improvement-10-1.9095.hdf5\n",
            "Epoch 11/20\n",
            "163681/163681 [==============================] - 308s 2ms/step - loss: 1.8982\n",
            "\n",
            "Epoch 00011: loss improved from 1.90947 to 1.89824, saving model to weights-improvement-11-1.8982.hdf5\n",
            "Epoch 12/20\n",
            "163681/163681 [==============================] - 307s 2ms/step - loss: 1.8829\n",
            "\n",
            "Epoch 00012: loss improved from 1.89824 to 1.88292, saving model to weights-improvement-12-1.8829.hdf5\n",
            "Epoch 13/20\n",
            "163681/163681 [==============================] - 305s 2ms/step - loss: 1.8742\n",
            "\n",
            "Epoch 00013: loss improved from 1.88292 to 1.87421, saving model to weights-improvement-13-1.8742.hdf5\n",
            "Epoch 14/20\n",
            "163681/163681 [==============================] - 306s 2ms/step - loss: 1.8618\n",
            "\n",
            "Epoch 00014: loss improved from 1.87421 to 1.86176, saving model to weights-improvement-14-1.8618.hdf5\n",
            "Epoch 15/20\n",
            "163681/163681 [==============================] - 305s 2ms/step - loss: 1.8531\n",
            "\n",
            "Epoch 00015: loss improved from 1.86176 to 1.85306, saving model to weights-improvement-15-1.8531.hdf5\n",
            "Epoch 16/20\n",
            "163681/163681 [==============================] - 305s 2ms/step - loss: 1.8375\n",
            "\n",
            "Epoch 00016: loss improved from 1.85306 to 1.83755, saving model to weights-improvement-16-1.8375.hdf5\n",
            "Epoch 17/20\n",
            "163681/163681 [==============================] - 308s 2ms/step - loss: 1.8309\n",
            "\n",
            "Epoch 00017: loss improved from 1.83755 to 1.83085, saving model to weights-improvement-17-1.8309.hdf5\n",
            "Epoch 18/20\n",
            "163681/163681 [==============================] - 309s 2ms/step - loss: 1.8233\n",
            "\n",
            "Epoch 00018: loss improved from 1.83085 to 1.82327, saving model to weights-improvement-18-1.8233.hdf5\n",
            "Epoch 19/20\n",
            "163681/163681 [==============================] - 306s 2ms/step - loss: 1.8109\n",
            "\n",
            "Epoch 00019: loss improved from 1.82327 to 1.81088, saving model to weights-improvement-19-1.8109.hdf5\n",
            "Epoch 20/20\n",
            "163681/163681 [==============================] - 303s 2ms/step - loss: 1.8029\n",
            "\n",
            "Epoch 00020: loss improved from 1.81088 to 1.80291, saving model to weights-improvement-20-1.8029.hdf5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7f4eb01c62b0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QG7PkkZsdKIC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Generating Text with the trained model\n",
        "# load the network weights\n",
        "filename = \"weights-improvement-20-2.0876.hdf5\"\n",
        "model.load_weights(filename)\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ESFYicZtdKIS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#reverse mapping from id to chars\n",
        "\n",
        "int_to_char = dict((i, c) for i, c in enumerate(chars))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XfHYe7a7dKIr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "outputId": "a6b05a24-d378-4faf-c137-3d9c3e8f221d"
      },
      "source": [
        "import sys\n",
        "# pick a random seed\n",
        "start = numpy.random.randint(0, len(dataX)-1)\n",
        "pattern = dataX[start]\n",
        "print (\"Seed:\")\n",
        "print (\"\\\"\", ''.join([int_to_char[value] for value in pattern]), \"\\\"\")\n",
        "# generate characters\n",
        "for i in range(1000):\n",
        "\tx = numpy.reshape(pattern, (1, len(pattern), 1))\n",
        "\tx = x / float(n_vocab)\n",
        "\tprediction = model.predict(x, verbose=0)\n",
        "\tindex = numpy.argmax(prediction)\n",
        "\tresult = int_to_char[index]\n",
        "\tseq_in = [int_to_char[value] for value in pattern]\n",
        "\tsys.stdout.write(result)\n",
        "\tpattern.append(index)\n",
        "\tpattern = pattern[1:len(pattern)]\n",
        "print (\"\\nDone.\")"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Seed:\n",
            "\" isk or other medium, a\n",
            "computer virus, or computer codes that damage or cannot be read by\n",
            "your equip \"\n",
            "r po the pooject gutenberg-tm electronic works in aoy coot thth the pooeect gutenberg-tm electronic works in aoy coot thth the pooeect gutenberg-tm electronic works in aoy coot thth the pooeect gutenberg-tm electronic works in aoy coot thth the pooeect gutenberg-tm electronic works in aoy coot thth the pooeect gutenberg-tm electronic works in aoy coot thth the pooeect gutenberg-tm electronic works in aoy coot thth the pooeect gutenberg-tm electronic works in aoy coot thth the pooeect gutenberg-tm electronic works in aoy coot thth the pooeect gutenberg-tm electronic works in aoy coot thth the pooeect gutenberg-tm electronic works in aoy coot thth the pooeect gutenberg-tm electronic works in aoy coot thth the pooeect gutenberg-tm electronic works in aoy coot thth the pooeect gutenberg-tm electronic works in aoy coot thth the pooeect gutenberg-tm electronic works in aoy coot thth the pooeect gutenberg-tm electronic works in aoy coot thth the pooeect gutenberg-tm electronic works in aoy co\n",
            "Done.\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}